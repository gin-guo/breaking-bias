{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T21:37:22.192928Z",
     "iopub.status.busy": "2025-03-10T21:37:22.192647Z",
     "iopub.status.idle": "2025-03-10T21:37:22.199000Z",
     "shell.execute_reply": "2025-03-10T21:37:22.198034Z",
     "shell.execute_reply.started": "2025-03-10T21:37:22.192906Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import time\n",
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "\n",
    "# NLP and transformers\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, AutoModel\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Set the random seed\n",
    "random.seed(7)\n",
    "\n",
    "# Check GPU availability\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"Sorry - GPU required!\")\n",
    "\n",
    "# Set logging level for transformers\n",
    "logging.getLogger('transformers').setLevel(logging.ERROR)\n",
    "\n",
    "# Pandas display options\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import input data (topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T21:30:54.192311Z",
     "iopub.status.busy": "2025-03-10T21:30:54.191972Z",
     "iopub.status.idle": "2025-03-10T21:30:54.208020Z",
     "shell.execute_reply": "2025-03-10T21:30:54.207343Z",
     "shell.execute_reply.started": "2025-03-10T21:30:54.192282Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1097671</td>\n",
       "      <td>Compare and contrast the importance of self-reliance and adaptability in healthcare.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1726150</td>\n",
       "      <td>Evaluate the effectiveness of management consulting in addressing conflicts within marketing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3211968</td>\n",
       "      <td>Discuss the role of self-reliance in achieving success in software engineering.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  \\\n",
       "0  1097671   \n",
       "1  1726150   \n",
       "2  3211968   \n",
       "\n",
       "                                                                                           topic  \n",
       "0           Compare and contrast the importance of self-reliance and adaptability in healthcare.  \n",
       "1  Evaluate the effectiveness of management consulting in addressing conflicts within marketing.  \n",
       "2                Discuss the role of self-reliance in achieving success in software engineering.  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"/kaggle/input/llms-you-cant-please-them-all/test.csv\")\n",
    "submission_df = pd.read_csv('/kaggle/input/llms-you-cant-please-them-all/sample_submission.csv')\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T21:32:55.939055Z",
     "iopub.status.busy": "2025-03-10T21:32:55.938731Z",
     "iopub.status.idle": "2025-03-10T21:32:59.464273Z",
     "shell.execute_reply": "2025-03-10T21:32:59.463654Z",
     "shell.execute_reply.started": "2025-03-10T21:32:55.939025Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2ebe7f7d1f4edbb5cad6787fe9e7c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Clear GPU memory and delete existing objects if they exist\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "for obj in ['model', 'pipe', 'tokenizer']:\n",
    "    if obj in globals():\n",
    "        del globals()[obj]\n",
    "\n",
    "# Model configuration\n",
    "model_name = '/kaggle/input/phi-3.5-mini-instruct/pytorch/default/1'\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Load pre-trained word embedding model\n",
    "embed_model = SentenceTransformer('/kaggle/input/all-minilm-l6-v2transformers/pytorch/default/1/all-MiniLM-L6-v2', device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T21:44:42.984932Z",
     "iopub.status.busy": "2025-03-10T21:44:42.984544Z",
     "iopub.status.idle": "2025-03-10T21:44:42.989840Z",
     "shell.execute_reply": "2025-03-10T21:44:42.988956Z",
     "shell.execute_reply.started": "2025-03-10T21:44:42.984902Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "max_new_tokens = 200  # Maximum length of generated text (can be overridden)\n",
    "temperature = 0.7     # Higher temperature = more random/creative outputs\n",
    "top_p = 0.7           # Nucleus sampling parameter for more diverse outputs (1.0 disables filtering)\n",
    "\n",
    "# Create pipeline with parameters\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    trust_remote_code=True,\n",
    "    max_new_tokens=max_new_tokens,\n",
    "    temperature=temperature,\n",
    "    top_p=top_p,\n",
    "    do_sample=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essay generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T21:47:30.208632Z",
     "iopub.status.busy": "2025-03-10T21:47:30.208274Z",
     "iopub.status.idle": "2025-03-10T21:47:30.214277Z",
     "shell.execute_reply": "2025-03-10T21:47:30.213415Z",
     "shell.execute_reply.started": "2025-03-10T21:47:30.208604Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_corpus_essay(topic, max_tokens=None):\n",
    "    \"\"\"\n",
    "    Generates an essay on a given topic using a language model.\n",
    "    \n",
    "    Args:\n",
    "        topic (str): The topic for which the essay is to be generated.\n",
    "        max_tokens (int, optional): The maximum number of tokens to generate. \n",
    "                                     If None, the model will generate the default number of tokens.\n",
    "    \n",
    "    Returns:\n",
    "        str: The generated essay on the given topic.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set the prompt for the topic\n",
    "    prompt = f\"Write about {topic} in less than 180 words.\"\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    # Define the generation parameters\n",
    "    generation_params = {}\n",
    "    if max_tokens:\n",
    "        generation_params['max_new_tokens'] = max_tokens\n",
    "    \n",
    "    # Generate the response\n",
    "    output = pipe(messages, **generation_params)[0]\n",
    "    essay = output['generated_text'][-1]['content']\n",
    "    \n",
    "    return essay\n",
    "\n",
    "def add_noise_to_text(text, epsilon=0.05):\n",
    "    \"\"\"\n",
    "    Adds Gaussian noise to the word embeddings of the input text and reconstructs the noisy text.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text to which noise will be added.\n",
    "        epsilon (float, optional): The standard deviation of the Gaussian noise to apply. Default is 0.05.\n",
    "    \n",
    "    Returns:\n",
    "        str: The noisy version of the input text with added randomness.\n",
    "    \"\"\"\n",
    "    \n",
    "    words = word_tokenize(text)\n",
    "    word_embeddings = embed_model.encode(words, convert_to_numpy=True)\n",
    "    \n",
    "    # Apply Gaussian noise\n",
    "    noise = np.random.normal(0, epsilon, word_embeddings.shape)\n",
    "    noisy_embeddings = word_embeddings + noise\n",
    "    \n",
    "    # Compute cosine similarity and find closest words\n",
    "    similarities = cosine_similarity(noisy_embeddings, word_embeddings)\n",
    "    noisy_words = [words[i] for i in similarities.argmax(axis=1)]\n",
    "    \n",
    "    # Reconstruct the noisy text\n",
    "    noisy_text = \" \".join(noisy_words)\n",
    "    return noisy_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate essays and output to submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T21:52:02.618764Z",
     "iopub.status.busy": "2025-03-10T21:52:02.618476Z",
     "iopub.status.idle": "2025-03-10T21:52:47.720361Z",
     "shell.execute_reply": "2025-03-10T21:52:47.719696Z",
     "shell.execute_reply.started": "2025-03-10T21:52:02.618741Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f69bda0a4184238a23b95df8abb1e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de409ba99204d2c8a421df033d524a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08fea95219a84900ae2cdb201ec957e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "baseline_essays = []\n",
    "noisy_essays = []\n",
    "for idx, row in test_df.iterrows():\n",
    "    essay = generate_corpus_essay(row['topic'], max_new_tokens)\n",
    "    baseline_essays.append(essay)\n",
    "\n",
    "    noisy_essay = add_noise_to_text(essay)\n",
    "    noisy_essays.append(noisy_essay)\n",
    "    # print(f\"Essay for topic '{row['topic']}':\\n{noisy_essay}\\n{'-'*80}\\n\")\n",
    "\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    \"id\": test_df[\"id\"],\n",
    "    \"essay\": noisy_essays\n",
    "})\n",
    "\n",
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T04:28:01.437906Z",
     "iopub.status.busy": "2025-03-05T04:28:01.437668Z",
     "iopub.status.idle": "2025-03-05T04:28:01.452517Z",
     "shell.execute_reply": "2025-03-05T04:28:01.451858Z",
     "shell.execute_reply.started": "2025-03-05T04:28:01.437886Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print (submission_df['essay'].values)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 10369658,
     "isSourceIdPinned": false,
     "sourceId": 83035,
     "sourceType": "competition"
    },
    {
     "datasetId": 6463322,
     "sourceId": 10442279,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4581967,
     "sourceId": 10982248,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 123513,
     "modelInstanceId": 99348,
     "sourceId": 118141,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 76277,
     "modelInstanceId": 72240,
     "sourceId": 85979,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 262985,
     "modelInstanceId": 241345,
     "sourceId": 281681,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
